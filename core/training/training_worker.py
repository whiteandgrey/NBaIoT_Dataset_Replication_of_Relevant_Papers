import sys
import os
import json
import time
import weakref
from typing import Dict, List, Optional
import numpy as np
from PyQt5.QtCore import QThread, QMutex

from config import Config
from data_processor import NBaIoTDataProcessor
from model import Autoencoder
from trainer import AutoencoderTrainer
from visualizer import ScientificVisualizer
from core.signals import TrainingSignals


def create_training_control_callback(tf_Callback):
    """
    åŠ¨æ€åˆ›å»ºTrainingControlCallbackç±»
    
    Args:
        tf_Callback: TensorFlowå›è°ƒç±»
        
    Returns:
        TrainingControlCallbackç±»
    """
    class TrainingControlCallback(tf_Callback):
        """
        è‡ªå®šä¹‰å›è°ƒç”¨äºæ§åˆ¶è®­ç»ƒæµç¨‹
        å®ç°å¯é çš„æš‚åœ/åœæ­¢åŠŸèƒ½
        """
        
        def __init__(self, worker_signals, worker_ref):
            """
            åˆå§‹åŒ–å›è°ƒ
            
            Args:
                worker_signals: è®­ç»ƒä¿¡å·å¯¹è±¡
                worker_ref: å¯¹TrainingWorkerçš„å¼±å¼•ç”¨ï¼Œç”¨äºæ£€æŸ¥çŠ¶æ€
            """
            super().__init__()
            self.worker_signals = worker_signals
            self.worker_ref = worker_ref
            self.epoch_data = {}
            
        def on_epoch_begin(self, epoch, logs=None):
            """
            æ¯ä¸ªepochå¼€å§‹æ—¶æ£€æŸ¥åœæ­¢çŠ¶æ€
            """
            worker = self.worker_ref()
            if worker is not None:
                if worker.should_stop:
                    self.model.stop_training = True
                    self.worker_signals.log.emit("ğŸ›‘ åœæ­¢ä¿¡å·å·²æ”¶åˆ°ï¼Œæ­£åœ¨åœæ­¢è®­ç»ƒ...")
        
        def on_epoch_end(self, epoch, logs=None):
            """
            æ¯ä¸ªepochç»“æŸæ—¶æ£€æŸ¥æš‚åœçŠ¶æ€å¹¶å‘é€æ•°æ®
            """
            worker = self.worker_ref()
            if worker is None:
                return
                
            # å‘é€epochå®Œæˆä¿¡å·
            if logs:
                self.epoch_data = {
                    'epoch': epoch + 1,
                    'train_loss': float(logs.get('loss', 0)),
                    'val_loss': float(logs.get('val_loss', logs.get('loss', 0))),
                    'phase': getattr(worker, 'current_phase', 'Training'),
                    'total_epochs': getattr(worker, 'total_epochs', 100)
                }
                self.worker_signals.epoch_completed.emit(self.epoch_data)
            
            # æ£€æŸ¥æš‚åœçŠ¶æ€
            if worker.is_paused:
                self.worker_signals.status_update.emit("å·²æš‚åœ - ç­‰å¾…æ¢å¤...")
                while worker.is_paused and not worker.should_stop:
                    time.sleep(0.1)
                    
            # æ£€æŸ¥åœæ­¢çŠ¶æ€
            if worker.should_stop:
                self.model.stop_training = True
                
            return super().on_epoch_end(epoch, logs)
        
        def on_batch_end(self, batch, logs=None):
            """
            æ¯ä¸ªbatchç»“æŸæ—¶æ£€æŸ¥çŠ¶æ€
            """
            worker = self.worker_ref()
            if worker is None:
                return
                
            if worker.should_stop:
                self.model.stop_training = True
                return
                
            if worker.is_paused:
                while worker.is_paused and not worker.should_stop:
                    time.sleep(0.05)
    
    return TrainingControlCallback


class TrainingWorker(QThread):
    """
    è®­ç»ƒå·¥ä½œçº¿ç¨‹ - åœ¨åå°æ‰§è¡Œè®­ç»ƒä»»åŠ¡
    """
    
    def __init__(self, config: Dict, signals: TrainingSignals):
        """
        åˆå§‹åŒ–è®­ç»ƒå·¥ä½œçº¿ç¨‹
        
        Args:
            config: è®­ç»ƒé…ç½®
            signals: è®­ç»ƒä¿¡å·å¯¹è±¡
        """
        super().__init__()
        self.config = config
        self.signals = signals
        self.is_paused = False
        self.should_stop = False
        self.is_running = False
        self.mutex = QMutex()
        
        # è®­ç»ƒé˜¶æ®µè·Ÿè¸ª
        self.current_phase = "åˆå§‹è®­ç»ƒ"
        self.total_epochs = 100
        
        # TensorFlowæ¨¡å—å’Œå›è°ƒç±»ï¼ˆå»¶è¿Ÿå¯¼å…¥ï¼‰
        self.tf = None
        self.tf_Callback = None
        self.tf_EarlyStopping = None
        self.tf_ReduceLROnPlateau = None
        
    def run(self):
        """
        æ‰§è¡Œè®­ç»ƒ
        """
        self.is_running = True
        self.should_stop = False
        self.is_paused = False
        
        try:
            # é¦–å…ˆè®¾ç½®ç¯å¢ƒï¼ˆå¿…é¡»åœ¨å¯¼å…¥TensorFlowä¹‹å‰ï¼‰
            self._setup_environment()
            
            # ç„¶åå¯¼å…¥TensorFlowï¼ˆç¡®ä¿åœ¨è®¾ç½®ç¯å¢ƒå˜é‡åæ‰å¯¼å…¥ï¼‰
            import tensorflow as tf_module
            from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau
            
            # ä¿å­˜TensorFlowæ¨¡å—å’Œå›è°ƒç±»åˆ°å®ä¾‹å˜é‡
            self.tf = tf_module
            self.tf_Callback = Callback
            self.tf_EarlyStopping = EarlyStopping
            self.tf_ReduceLROnPlateau = ReduceLROnPlateau
            
            print(f"âœ… TensorFlow imported successfully")
            print(f"   TensorFlow version: {tf_module.__version__}")
            print(f"   GPU available: {tf_module.config.list_physical_devices('GPU')}")
            
            # åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
            data_processor = NBaIoTDataProcessor(Config)
            
            # è·å–è¦è®­ç»ƒçš„è®¾å¤‡åˆ—è¡¨
            devices_to_train = self._get_devices_to_train(data_processor)
            
            if not devices_to_train:
                self.signals.error.emit("æ²¡æœ‰é€‰æ‹©è¦è®­ç»ƒçš„è®¾å¤‡")
                self.is_running = False
                return
            
            # åˆå§‹åŒ–å¯è§†åŒ–å™¨
            visualizer = ScientificVisualizer(Config)
            
            # è®°å½•æ€»ç»“æœ
            all_results = []
            total_start_time = time.time()
            
            # éå†è®¾å¤‡è¿›è¡Œè®­ç»ƒ
            for i, device_name in enumerate(devices_to_train):
                if self.should_stop:
                    break
                    
                self._wait_if_paused()
                
                if self.should_stop:
                    break
                    
                self.signals.status_update.emit(f"æ­£åœ¨è®­ç»ƒ: {device_name} ({i+1}/{len(devices_to_train)})")
                self.signals.started.emit(device_name)
                
                # è®­ç»ƒå•ä¸ªè®¾å¤‡
                result = self._train_device(
                    device_name, data_processor, visualizer
                )
                
                if result:
                    all_results.append(result)
                
                if self.should_stop:
                    break
                    
                self.signals.device_completed.emit({
                    'device': device_name,
                    'result': result,
                    'progress': (i + 1) / len(devices_to_train) * 100
                })
            
            # è®­ç»ƒå®Œæˆ
            total_time = time.time() - total_start_time
            
            self.signals.finished.emit({
                'results': all_results,
                'total_time': total_time,
                'total_devices': len(all_results)
            })
            
        except Exception as e:
            import traceback
            error_msg = f"è®­ç»ƒé”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            self.signals.error.emit(error_msg)
        finally:
            self.is_running = False
    
    def _wait_if_paused(self):
        """
        ç­‰å¾…æ¢å¤
        """
        while self.is_paused and not self.should_stop:
            time.sleep(0.1)
    
    def _setup_environment(self):
        """
        è®¾ç½®ç¯å¢ƒ
        """
        Config.USE_GPU = self.config.get('use_gpu', False)
        Config.GPU_DEVICES = self.config.get('gpu_devices', "0")
        Config.GPU_MEMORY_LIMIT = self.config.get('gpu_memory_limit')
        Config.DATA_ROOT = self.config.get('data_root', Config.DATA_ROOT)
        Config.OUTPUT_DIR = self.config.get('output_dir', Config.OUTPUT_DIR)
        
        # è°ƒç”¨Config.setup_environment()æ¥è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨å¯¼å…¥TensorFlowä¹‹å‰ï¼‰
        Config.setup_environment()
        
        Config.DEFAULT_LEARNING_RATE = self.config.get('learning_rate', 0.001)
        Config.DEFAULT_EPOCHS = self.config.get('epochs', 100)
        Config.DEFAULT_BATCH_SIZE = self.config.get('batch_size', 64)
        
        Config.ENCODER_RATIOS = self.config.get('encoder_ratios', [0.75, 0.50, 0.33, 0.25])
        Config.DECODER_RATIOS = self.config.get('decoder_ratios', [0.33, 0.50, 0.75, 1.0])
        Config.ACTIVATION = self.config.get('activation', 'relu')
        Config.USE_BATCH_NORM = self.config.get('use_batch_norm', False)
        Config.DROPOUT_RATE = self.config.get('dropout_rate', 0.0)
        
        Config.EARLY_STOPPING_PATIENCE = self.config.get('early_stopping_patience', 15)
        Config.REDUCE_LR_PATIENCE = self.config.get('reduce_lr_patience', 10)
        
        Config.LEARNING_RATES = self.config.get('learning_rates', [1e-4, 5e-4, 1e-3, 5e-3, 1e-2])
        Config.EPOCHS_OPTIONS = self.config.get('epochs_options', [50, 100, 150, 200])
        
        # æ–‡ä»¶ä¿å­˜é…ç½®
        Config.SAVE_LOG_FILE = self.config.get('save_log_file', True)
        Config.SAVE_MODEL = self.config.get('save_model', True)
        Config.SAVE_BEST_MODEL_ONLY = self.config.get('save_best_model_only', True)
        Config.SAVE_TRAINING_HISTORY = self.config.get('save_training_history', True)
        Config.SAVE_HYPERPARAMETER_TUNING_RESULTS = self.config.get('save_hyperparam_results', True)
        Config.SAVE_SCALER = self.config.get('save_scaler', True)
        Config.SAVE_TENSORBOARD_LOGS = self.config.get('save_tensorboard', False)
        Config.PLOT_SAVE = self.config.get('plot_save', True)
        
        # å›¾è¡¨ç±»å‹é…ç½®
        Config.PLOT_TRAINING_LOSS_CURVE = self.config.get('plot_training_loss_curve', True)
        Config.PLOT_TRAINING_MAE_CURVE = self.config.get('plot_training_mae_curve', True)
        Config.PLOT_TRAINING_LR_CURVE = self.config.get('plot_training_lr_curve', True)
        Config.PLOT_HYPERPARAM_HEATMAP = self.config.get('plot_hyperparam_heatmap', True)
        Config.PLOT_HYPERPARAM_CONTOUR = self.config.get('plot_hyperparam_contour', True)
        Config.PLOT_HYPERPARAM_3D = self.config.get('plot_hyperparam_3d', False)
        Config.PLOT_LOSS_DISTRIBUTION = self.config.get('plot_loss_distribution', True)
        Config.PLOT_LOSS_HISTOGRAM = self.config.get('plot_loss_histogram', True)
        Config.PLOT_LOSS_BOX_PLOT = self.config.get('plot_loss_boxplot', True)
        Config.PLOT_LOSS_VIOLIN_PLOT = self.config.get('plot_loss_violin', True)
        Config.PLOT_PERFORMANCE_METRICS = self.config.get('plot_performance_metrics', True)
        Config.PLOT_LEARNING_RATE_SCHEDULE = self.config.get('plot_lr_schedule', True)
        Config.PLOT_GRADIENT_FLOW = self.config.get('plot_gradient_flow', False)
        Config.PLOT_DATA_DISTRIBUTION = self.config.get('plot_data_distribution', True)
        Config.PLOT_FEATURE_CORRELATION = self.config.get('plot_feature_correlation', False)
        Config.PLOT_PCA_VISUALIZATION = self.config.get('plot_pca_visualization', False)
        Config.PLOT_TRAINING_TIME_ANALYSIS = self.config.get('plot_training_time_analysis', True)
        Config.PLOT_EPOCH_TIME_DISTRIBUTION = self.config.get('plot_epoch_time_distribution', True)
        Config.PLOT_DEVICE_COMPARISON = self.config.get('plot_device_comparison', True)
        Config.PLOT_PHASE_COMPARISON = self.config.get('plot_phase_comparison', True)
        Config.PLOT_PERFORMANCE_RANKING = self.config.get('plot_performance_ranking', True)
        Config.PLOT_COMPREHENSIVE_SUMMARY = self.config.get('plot_comprehensive_summary', True)
        Config.PLOT_TRAINING_REPORT = self.config.get('plot_training_report', True)
        
        # æ³¨æ„ï¼šConfig.setup_environment()å·²åœ¨å¯¼å…¥æ—¶è°ƒç”¨ï¼Œè¿™é‡Œä¸å†é‡å¤è°ƒç”¨
        # åªéœ€è¦è®¾ç½®TensorFlowå’Œç›®å½•
        Config.setup_tensorflow()
        Config.setup_directories()
        
    def _get_devices_to_train(self, data_processor) -> List[str]:
        """
        è·å–è¦è®­ç»ƒçš„è®¾å¤‡åˆ—è¡¨
        """
        selected_devices = self.config.get('selected_devices', [])
        
        if not selected_devices:
            return data_processor.get_available_devices()
        
        available = data_processor.get_available_devices()
        valid_devices = [d for d in selected_devices if d in available]
        
        if not valid_devices:
            return available
        
        return valid_devices
    
    def _train_device(self, device_name: str, data_processor, visualizer) -> Optional[Dict]:
        """
        è®­ç»ƒå•ä¸ªè®¾å¤‡
        
        Args:
            device_name: è®¾å¤‡åç§°
            data_processor: æ•°æ®å¤„ç†å™¨
            visualizer: å¯è§†åŒ–å™¨
            
        Returns:
            è®­ç»ƒç»“æœ
        """
        import weakref
        
        # åŠ è½½æ•°æ®
        self.signals.log.emit(f"ğŸ“¥ æ­£åœ¨åŠ è½½ {device_name} çš„æ•°æ®...")
        data = data_processor.load_device_data(device_name)
        
        if data is None:
            self.signals.error.emit(f"âŒ æ— æ³•åŠ è½½ {device_name} çš„æ•°æ®")
            return None
        
        # åˆ’åˆ†æ•°æ®
        if Config.TIME_ORDERED:
            DStrn, DSopt, DStst = data_processor.split_data_chronologically(data)
        else:
            DStrn, DSopt, DStst = data_processor.split_data_randomly(data)
        
        # é¢„å¤„ç†æ•°æ®
        self.signals.log.emit(f"ğŸ”§ æ­£åœ¨é¢„å¤„ç†æ•°æ®...")
        DStrn_processed = data_processor.preprocess_data(DStrn, fit_scaler=True)
        DSopt_processed = data_processor.preprocess_data(DSopt, fit_scaler=False)
        
        # åˆ›å»ºè®­ç»ƒæ•°æ®
        (X_train, y_train), (X_val, y_val) = data_processor.create_numpy_datasets(
            DStrn_processed, DSopt_processed
        )
        
        # è·å–æ•°æ®ä¿¡æ¯
        data_info = {
            'device_name': device_name,
            'n_features': data.shape[1],
            'n_samples': len(data),
            'train_samples': len(DStrn),
            'val_samples': len(DSopt),
            'test_samples': len(DStst),
        }
        
        # ä½¿ç”¨å®é™…æ•°æ®çš„ç‰¹å¾ç»´åº¦æ¥æ„å»ºæ¨¡å‹
        actual_input_dim = data.shape[1]
        self.signals.log.emit(f"ğŸ“ å®é™…æ•°æ®ç‰¹å¾ç»´åº¦: {actual_input_dim}")
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = AutoencoderTrainer(Config, device_name)
        
        # åˆ›å»ºå›è°ƒå¯¹è±¡
        TrainingControlCallback = create_training_control_callback(self.tf_Callback)
        control_callback = TrainingControlCallback(self.signals, weakref.ref(self))
        
        # é˜¶æ®µ1: åˆå§‹è®­ç»ƒ
        self.signals.log.emit(f"ğŸš€ å¼€å§‹åˆå§‹è®­ç»ƒ...")
        self.signals.status_update.emit(f"é˜¶æ®µ1: åˆå§‹è®­ç»ƒ")
        self.current_phase = "åˆå§‹è®­ç»ƒ"
        
        initial_start_time = time.time()
        initial_result = self._train_with_callback(
            trainer, X_train, y_train, X_val, y_val,
            phase_name="åˆå§‹è®­ç»ƒ",
            total_epochs=Config.DEFAULT_EPOCHS,
            control_callback=control_callback,
            input_dim=actual_input_dim
        )
        initial_training_time = time.time() - initial_start_time
        
        # ä¿å­˜åˆå§‹è®­ç»ƒå†å²
        trainer.training_history['initial_train'] = {
            'history': initial_result['history'],
            'training_time': initial_training_time,
            'best_val_loss': initial_result['best_val_loss']
        }
        
        self.signals.log.emit(f"âœ… åˆå§‹è®­ç»ƒå®Œæˆã€‚æœ€ä½³æŸå¤±: {initial_result['best_val_loss']:.6f}")
        
        if self.should_stop:
            return None
        
        # é˜¶æ®µ2: è¶…å‚æ•°è°ƒä¼˜
        self.signals.log.emit(f"ğŸ” å¼€å§‹è¶…å‚æ•°è°ƒä¼˜...")
        self.signals.status_update.emit(f"é˜¶æ®µ2: è¶…å‚æ•°è°ƒä¼˜")
        self.current_phase = "è¶…å‚æ•°è°ƒä¼˜"
        
        tuning_result = self._train_with_hyperparameter_tuning(
            trainer, X_train, y_train, X_val, y_val,
            control_callback=control_callback,
            input_dim=actual_input_dim
        )
        
        self.signals.log.emit(f"âœ… è¶…å‚æ•°è°ƒä¼˜å®Œæˆã€‚æœ€ä½³å‚æ•°: LR={tuning_result['lr']:.6f}, Epochs={tuning_result['epochs']}")
        
        if self.should_stop:
            return None
        
        # é˜¶æ®µ3: æœ€ç»ˆè®­ç»ƒ
        self.signals.log.emit(f"ğŸ¯ å¼€å§‹æœ€ç»ˆè®­ç»ƒ...")
        self.signals.status_update.emit(f"é˜¶æ®µ3: æœ€ç»ˆè®­ç»ƒ")
        self.current_phase = "æœ€ç»ˆè®­ç»ƒ"
        
        # åˆå¹¶è®­ç»ƒå’ŒéªŒè¯æ•°æ®
        X_combined = np.concatenate([X_train, X_val], axis=0)
        y_combined = np.concatenate([y_train, y_val], axis=0)
        
        final_start_time = time.time()
        final_result = self._train_with_callback(
            trainer, X_combined, y_combined, None, None,
            phase_name="æœ€ç»ˆè®­ç»ƒ",
            total_epochs=trainer.training_history['best_params']['epochs'] if trainer.training_history.get('best_params') else Config.DEFAULT_EPOCHS,
            control_callback=control_callback,
            input_dim=actual_input_dim
        )
        final_training_time = time.time() - final_start_time
        
        # ä¿å­˜æœ€ç»ˆè®­ç»ƒå†å²
        trainer.training_history['final_train'] = {
            'history': final_result['history'],
            'training_time': final_training_time,
            'best_val_loss': final_result['best_val_loss']
        }
        
        self.signals.log.emit(f"âœ… æœ€ç»ˆè®­ç»ƒå®Œæˆã€‚æœ€ç»ˆæŸå¤±: {final_result['best_val_loss']:.6f}")
        
        # ä¿å­˜æ¨¡å‹ï¼ˆä¿®å¤bugï¼šæ·»åŠ å®é™…çš„æ¨¡å‹ä¿å­˜ä»£ç ï¼‰
        if Config.SAVE_MODEL:
            model_path = os.path.join(trainer.device_output_dir, 'final_model.h5')
            trainer.model.save(model_path)
            self.signals.log.emit(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        
        # ç”Ÿæˆå¯è§†åŒ–
        self.signals.log.emit(f"ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        device_start_time = time.time()
        visualizer.generate_all_plots(trainer, device_name, data_info)

        # ä¿å­˜scaler
        if Config.SAVE_SCALER:
            scaler_path = os.path.join(trainer.device_output_dir, 'scaler.pkl')
            data_processor.save_scaler(scaler_path)
        
        # è¿”å›ç»“æœï¼ˆå®‰å…¨è®¿é—®training_historyä¸­çš„æ•°æ®ï¼‰
        final_train_data = trainer.training_history.get('final_train') or {}
        return {
            'device_name': device_name,
            'best_params': trainer.training_history.get('best_params'),
            'best_val_loss': trainer.training_history['best_val_loss'],
            'final_train_loss': final_result['best_val_loss'],
            'training_time': final_train_data.get('training_time', 0),
            'data_info': data_info,
            'model_path': os.path.join(trainer.device_output_dir, 'final_model.h5')
        }
    
    def _train_with_callback(self, trainer, X_train, y_train, X_val, y_val, 
                             phase_name: str, total_epochs: int,
                             control_callback = None,
                             input_dim: int = None) -> Dict:
        """
        å¸¦å›è°ƒçš„è®­ç»ƒ
        """
        import weakref
        
        self.current_phase = phase_name
        self.total_epochs = total_epochs
        
        # åˆ›å»ºæ¨¡å‹ï¼ˆä½¿ç”¨å®é™…è¾“å…¥ç»´åº¦ï¼‰
        autoencoder = Autoencoder(Config)
        model = autoencoder.build(input_dim=input_dim)
        trainer.model = model
        
        # ç¼–è¯‘æ¨¡å‹
        lr = trainer.config.DEFAULT_LEARNING_RATE
        model.compile(
            optimizer=self.tf.keras.optimizers.Adam(learning_rate=lr),
            loss='mse',
            metrics=['mae']
        )
        
        # åˆ›å»ºå›è°ƒ
        callbacks = [
            self.tf_EarlyStopping(
                monitor='val_loss' if X_val is not None else 'loss',
                patience=trainer.config.EARLY_STOPPING_PATIENCE,
                mode='min',
                min_delta=trainer.config.MIN_DELTA,
                restore_best_weights=True,
                verbose=0
            ),
            self.tf_ReduceLROnPlateau(
                monitor='val_loss' if X_val is not None else 'loss',
                factor=trainer.config.REDUCE_LR_FACTOR,
                patience=trainer.config.REDUCE_LR_PATIENCE,
                min_lr=1e-6,
                mode='min',
                verbose=0
            )
        ]
        
        if control_callback is None:
            TrainingControlCallback = create_training_control_callback(self.tf_Callback)
            control_callback = TrainingControlCallback(self.signals, weakref.ref(self))
        callbacks.append(control_callback)
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        if X_val is not None:
            validation_data = (X_val, y_val)
        else:
            validation_data = None
        
        # è®­ç»ƒæ¨¡å‹
        history = model.fit(
            X_train, y_train,
            validation_data=validation_data,
            epochs=total_epochs,
            batch_size=trainer.config.DEFAULT_BATCH_SIZE,
            callbacks=callbacks,
            verbose=0
        )
        
        # è·å–æœ€ä½³éªŒè¯æŸå¤±
        history_dict = history.history
        if 'val_loss' in history_dict:
            best_val_loss = min(history_dict['val_loss'])
        else:
            best_val_loss = history_dict['loss'][-1] if history_dict['loss'] else float('inf')
        
        return {
            'history': history_dict,
            'best_val_loss': best_val_loss
        }
    
    def _train_with_hyperparameter_tuning(self, trainer, X_train, y_train, X_val, y_val,
                                           control_callback = None,
                                           input_dim: int = None):
        """
        è¶…å‚æ•°è°ƒä¼˜ï¼ˆå¸¦å›¾è¡¨æ›´æ–°ï¼‰- ä¿®å¤ç‰ˆï¼ŒåŒ…å«training_time
        """
        import weakref
        
        results = []
        best_val_loss = float('inf')
        best_params = None
        
        # éå†è¶…å‚æ•°ç»„åˆ
        for lr in trainer.config.LEARNING_RATES:
            for epochs in trainer.config.EPOCHS_OPTIONS:
                if self.should_stop:
                    break
                    
                tuning_start_time = time.time()
                
                self.signals.log.emit(f"ğŸ§ª æµ‹è¯•: LR={lr:.6f}, Epochs={epochs}")
                self.signals.status_update.emit(f"è¶…å‚æ•°è°ƒä¼˜: LR={lr:.6f}, Epochs={epochs}")
                
                # é‡æ–°åˆ›å»ºæ¨¡å‹ï¼ˆä½¿ç”¨å®é™…è¾“å…¥ç»´åº¦ï¼‰
                autoencoder = Autoencoder(Config)
                model = autoencoder.build(input_dim=input_dim)
                trainer.model = model
                
                # ç¼–è¯‘æ¨¡å‹
                model.compile(
                    optimizer=self.tf.keras.optimizers.Adam(learning_rate=lr),
                    loss='mse',
                    metrics=['mae']
                )
                
                # åˆ›å»ºå›è°ƒ
                callbacks = [
                    self.tf_EarlyStopping(
                        monitor='val_loss',
                        patience=trainer.config.EARLY_STOPPING_PATIENCE,
                        mode='min',
                        min_delta=trainer.config.MIN_DELTA,
                        restore_best_weights=True,
                        verbose=0
                    )
                ]
                
                if control_callback is None:
                    TrainingControlCallback = create_training_control_callback(self.tf_Callback)
                    control_callback = TrainingControlCallback(self.signals, weakref.ref(self))
                
                # è®¾ç½®å½“å‰é˜¶æ®µ
                old_phase = self.current_phase
                self.current_phase = f"è¶…å‚æ•°è°ƒä¼˜ (LR={lr:.4f})"
                
                # è®­ç»ƒæ¨¡å‹
                history = model.fit(
                    X_train, y_train,
                    validation_data=(X_val, y_val),
                    epochs=epochs,
                    batch_size=trainer.config.DEFAULT_BATCH_SIZE,
                    callbacks=callbacks + [control_callback],
                    verbose=0
                )
                
                # æ¢å¤é˜¶æ®µåç§°
                self.current_phase = old_phase
                
                # è®¡ç®—è®­ç»ƒæ—¶é—´
                tuning_time = time.time() - tuning_start_time
                
                # è·å–ç»“æœ
                history_dict = history.history
                val_loss = min(history_dict['val_loss']) if 'val_loss' in history_dict else history_dict['loss'][-1]
                
                # è®°å½•ç»“æœï¼ˆåŒ…å«training_timeï¼‰
                result = {
                    'lr': lr,
                    'epochs': epochs,
                    'val_loss': val_loss,
                    'training_time': tuning_time  # ä¿®å¤ï¼šæ·»åŠ training_timeå­—æ®µ
                }
                results.append(result)
                
                # å‘é€epochå®Œæˆä¿¡å·
                if history_dict['loss']:
                    self.signals.epoch_completed.emit({
                        'epoch': len(history_dict['loss']),
                        'train_loss': history_dict['loss'][-1],
                        'val_loss': val_loss,
                        'phase': "è¶…å‚æ•°è°ƒä¼˜",
                        'total_epochs': epochs
                    })
                
                # æ›´æ–°æœ€ä½³å‚æ•°
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    best_params = {'lr': lr, 'epochs': epochs}
                
                # å‘é€è¿›åº¦
                total_combinations = len(trainer.config.LEARNING_RATES) * len(trainer.config.EPOCHS_OPTIONS)
                current = results.index(result) + 1
                progress = current / total_combinations * 100
                self.signals.progress.emit({'progress': progress, 'loss': val_loss})
                
                self.signals.log.emit(f"   ç»“æœ: éªŒè¯æŸå¤±={val_loss:.6f}, æ—¶é—´={tuning_time:.2f}ç§’")
                
                self._wait_if_paused()
                
                if self.should_stop:
                    break
        
        # ä¿å­˜è°ƒä¼˜ç»“æœ
        trainer.training_history['hyperparameter_tuning'] = results
        trainer.training_history['best_params'] = best_params
        trainer.training_history['best_val_loss'] = best_val_loss
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        tuning_results_path = os.path.join(trainer.device_output_dir, 'hyperparameter_tuning.json')
        with open(tuning_results_path, 'w') as f:
            json.dump(results, f, indent=2)
        
        return best_params if best_params else {'lr': trainer.config.DEFAULT_LEARNING_RATE, 'epochs': trainer.config.DEFAULT_EPOCHS}
    
    def pause(self):
        """
        æš‚åœè®­ç»ƒ
        """
        self.mutex.lock()
        self.is_paused = True
        self.mutex.unlock()
        self.signals.status_update.emit("å·²æš‚åœ - ç‚¹å‡»ç»§ç»­æ¢å¤è®­ç»ƒ")
        
    def resume(self):
        """
        æ¢å¤è®­ç»ƒ
        """
        self.mutex.lock()
        self.is_paused = False
        self.mutex.unlock()
        self.signals.status_update.emit("æ­£åœ¨æ¢å¤è®­ç»ƒ...")
        
    def stop(self):
        """
        åœæ­¢è®­ç»ƒ
        """
        self.mutex.lock()
        self.should_stop = True
        self.is_paused = False
        self.mutex.unlock()
        self.signals.status_update.emit("æ­£åœ¨åœæ­¢è®­ç»ƒ...")
