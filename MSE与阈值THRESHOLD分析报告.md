# MSEè®¡ç®—ä¸é˜ˆå€¼ç®—æ³•åˆ†ææŠ¥å‘Š

## 1. MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰çš„å®šä¹‰

### 1.1 MSEçš„æ•°å­¦å®šä¹‰

**MSEï¼ˆMean Squared Errorï¼‰**ï¼š
```
MSE = (1/n) * Î£(y_true - y_pred)^2
```

**ä»£ç å®ç°**ï¼š
```python
# anomaly_detector.py ç¬¬82-83è¡Œ
# è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„MSE
mse = np.mean(np.power(data - reconstructed, 2), axis=1)
```

**è§£é‡Š**ï¼š
- `data`ï¼šåŸå§‹è¾“å…¥æ•°æ®ï¼ˆ115ç»´ç‰¹å¾å‘é‡ï¼‰
- `reconstructed`ï¼šè‡ªç¼–ç å™¨é‡å»ºçš„æ•°æ®ï¼ˆ115ç»´ç‰¹å¾å‘é‡ï¼‰
- `np.power(data - reconstructed, 2)`ï¼šè®¡ç®—æ¯ä¸ªç»´åº¦çš„é‡å»ºè¯¯å·®çš„å¹³æ–¹
- `np.mean(..., axis=1)`ï¼šå¯¹æ¯ä¸ªæ ·æœ¬çš„æ‰€æœ‰ç»´åº¦æ±‚å¹³å‡

**ç‰©ç†æ„ä¹‰**ï¼š
- MSEè¡¨ç¤ºè‡ªç¼–ç å™¨é‡å»ºæ•°æ®çš„å¹³å‡è¯¯å·®
- MSEè¶Šå°ï¼Œè¯´æ˜è‡ªç¼–ç å™¨é‡å»ºèƒ½åŠ›è¶Šå¥½
- MSEè¶Šå¤§ï¼Œè¯´æ˜è‡ªç¼–ç å™¨é‡å»ºèƒ½åŠ›è¶Šå·®

### 1.2 MSEçš„åˆ†å¸ƒç‰¹å¾

**æ­£æ€åˆ†å¸ƒå‡è®¾**ï¼š
- å¦‚æœè‡ªç¼–ç å™¨è®­ç»ƒè‰¯å¥½ï¼ŒMSEåº”è¯¥ç¬¦åˆæ­£æ€åˆ†å¸ƒ
- å¤§éƒ¨åˆ†æ ·æœ¬çš„MSEåº”è¯¥é›†ä¸­åœ¨å‡å€¼é™„è¿‘
- ç¦»ç¾¤å€¼ï¼ˆå¼‚å¸¸ï¼‰åº”è¯¥è¾ƒå°‘

**å¼‚å¸¸æ£€æµ‹åŸç†**ï¼š
- è‡ªç¼–ç å™¨åœ¨è‰¯æ€§æ•°æ®ä¸Šè®­ç»ƒï¼Œå­¦ä¹ è‰¯æ€§æ•°æ®çš„åˆ†å¸ƒ
- å¯¹äºè‰¯æ€§æ ·æœ¬ï¼Œé‡å»ºè¯¯å·®åº”è¯¥è¾ƒå°
- å¯¹äºæ”»å‡»æ ·æœ¬ï¼Œé‡å»ºè¯¯å·®åº”è¯¥è¾ƒå¤§ï¼ˆå› ä¸ºè‡ªç¼–ç å™¨æ²¡æœ‰è§è¿‡æ”»å‡»æ•°æ®ï¼‰
- é€šè¿‡è®¾ç½®é˜ˆå€¼ï¼ŒåŒºåˆ†è‰¯æ€§æ ·æœ¬å’Œæ”»å‡»æ ·æœ¬

## 2. å¼‚å¸¸é˜ˆå€¼è®¡ç®—åˆ†æ

### 2.1 å½“å‰é˜ˆå€¼ç®—æ³•

**ä»£ç å®ç°**ï¼š
```python
# anomaly_detector.py ç¬¬108-112è¡Œ
# è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
mean_mse = np.mean(mse_values)
std_mse = np.std(mse_values)

# è®¡ç®—é˜ˆå€¼
self.tr_threshold = mean_mse + std_mse
```

**é˜ˆå€¼å«ä¹‰**ï¼š
- `mean_mse`ï¼šDSoptæ•°æ®é›†ä¸ŠMSEçš„å‡å€¼
- `std_mse`ï¼šDSoptæ•°æ®é›†ä¸ŠMSEçš„æ ‡å‡†å·®
- `tr_threshold = mean_mse + std_mse`ï¼šå¼‚å¸¸é˜ˆå€¼

**åˆ¤å®šè§„åˆ™**ï¼š
- å¦‚æœMSE > tr_thresholdï¼Œåˆ™åˆ¤å®šä¸ºå¼‚å¸¸
- å¦åˆ™åˆ¤å®šä¸ºè‰¯æ€§

### 2.2 ä¸ºä»€ä¹ˆDSoptä¸Šçš„åˆå§‹å¼‚å¸¸å€™é€‰æ•°é‡é‚£ä¹ˆå¤šï¼Ÿ

**åŸå› åˆ†æ**ï¼š

1. **é˜ˆå€¼è®¾ç½®è¿‡é«˜**ï¼š
   - å½“å‰é˜ˆå€¼ï¼š`mean_mse + std_mse`
   - è¿™æ„å‘³ç€çº¦16%çš„æ ·æœ¬ä¼šè¢«åˆ¤å®šä¸ºå¼‚å¸¸ï¼ˆå‡è®¾æ­£æ€åˆ†å¸ƒï¼‰
   - å¦‚æœMSEåˆ†å¸ƒä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼Œå¯èƒ½å¯¼è‡´æ›´å¤šæ ·æœ¬è¢«åˆ¤å®šä¸ºå¼‚å¸¸

2. **MSEåˆ†å¸ƒä¸å‡åŒ€**ï¼š
   - å¦‚æœMSEåˆ†å¸ƒå³åï¼ˆé•¿å°¾ï¼‰ï¼Œå¯èƒ½å¯¼è‡´æ›´å¤šæ ·æœ¬è¢«åˆ¤å®šä¸ºå¼‚å¸¸
   - å¦‚æœMSEåˆ†å¸ƒå·¦åï¼Œå¯èƒ½å¯¼è‡´è¾ƒå°‘æ ·æœ¬è¢«åˆ¤å®šä¸ºå¼‚å¸¸

3. **è‡ªç¼–ç å™¨é‡å»ºèƒ½åŠ›ä¸è¶³**ï¼š
   - å¦‚æœè‡ªç¼–ç å™¨é‡å»ºèƒ½åŠ›ä¸è¶³ï¼Œè‰¯æ€§æ ·æœ¬çš„MSEå¯èƒ½è¾ƒå¤§
   - å¯¼è‡´é˜ˆå€¼è¾ƒé«˜ï¼Œæ›´å¤šæ ·æœ¬è¢«åˆ¤å®šä¸ºå¼‚å¸¸

### 2.3 éªŒè¯å»ºè®®

**æ·»åŠ MSEåˆ†å¸ƒåˆ†æ**ï¼š
```python
def calculate_anomaly_threshold(self, dsopt_data):
    """
    è®¡ç®—å¼‚å¸¸é˜ˆå€¼ tr*
    """
    print(f"\n{'=' * 60}")
    print("CALCULATING ANOMALY THRESHOLD (tr*)")
    print(f"{'=' * 60}")

    # è®¡ç®—DSoptä¸Šçš„MSE
    mse_values = self.calculate_reconstruction_error(dsopt_data)

    # è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
    mean_mse = np.mean(mse_values)
    std_mse = np.std(mse_values)
    
    # è®¡ç®—é˜ˆå€¼
    self.tr_threshold = mean_mse + std_mse
    
    print(f"ğŸ“Š DSopt MSE statistics:")
    print(f"   Mean: {mean_mse:.6f}")
    print(f"   Std: {std_mse:.6f}")
    print(f"   Calculated threshold tr*: {self.tr_threshold:.6f}")
    
    # æ·»åŠ MSEåˆ†å¸ƒåˆ†æ
    print(f"ğŸ“Š MSE distribution analysis:")
    print(f"   Percentiles:")
    for p in [50, 75, 90, 95, 99]:
        print(f"   {p}th percentile: {np.percentile(mse_values, p):.6f}")
    
    # è®¡ç®—åˆå§‹å¼‚å¸¸å€™é€‰æ•°é‡
    anomaly_decisions = (mse_values > tr_threshold).astype(int)
    print(f"ğŸ“Š Initial anomaly detection on DSopt:")
    print(f"   Total samples: {len(dsopt_data)}")
    print(f"   Initial anomaly candidates: {sum(anomaly_decisions)} ({sum(anomaly_decisions)/len(dsopt_data)*100:.2f}%)")
    
    return self.tr_threshold
```

## 3. æ»‘åŠ¨çª—å£ä¼˜åŒ–åˆ†æ

### 3.1 ä¸ºä»€ä¹ˆæ»‘åŠ¨çª—å£æ€»æ˜¯è¦è®¾ç½®æˆæœ€å¤§ï¼Ÿ

**åŸå› åˆ†æ**ï¼š

1. **åˆå§‹å¼‚å¸¸å€™é€‰æ•°é‡è¿‡å¤š**ï¼š
   - å¦‚æœDSoptä¸Šçš„åˆå§‹å¼‚å¸¸å€™é€‰æ•°é‡å¾ˆå¤šï¼ˆä¾‹å¦‚ï¼š> 10%ï¼‰
   - éœ€è¦å¾ˆå¤§çš„çª—å£å¤§å°æ‰èƒ½é€šè¿‡å¤šæ•°æŠ•ç¥¨æ¶ˆé™¤è¯¯æŠ¥
   - ä¾‹å¦‚ï¼šå¦‚æœæœ‰1000ä¸ªåˆå§‹å¼‚å¸¸å€™é€‰ï¼Œçª—å£å¤§å°ä¸º100æ—¶ï¼Œéœ€è¦è¶…è¿‡50ä¸ªå¼‚å¸¸å†³ç­–æ‰èƒ½åˆ¤å®šä¸ºå¼‚å¸¸

2. **å¤šæ•°æŠ•ç¥¨æœºåˆ¶çš„å±€é™æ€§**ï¼š
   - çª—å£å¤§å°ä¸ºNæ—¶ï¼Œéœ€è¦è¶…è¿‡N/2ä¸ªå¼‚å¸¸å†³ç­–æ‰èƒ½åˆ¤å®šä¸ºå¼‚å¸¸
   - å¦‚æœåˆå§‹å¼‚å¸¸å€™é€‰åˆ†å¸ƒè¾ƒå¹¿ï¼Œéœ€è¦æ›´å¤§çš„çª—å£å¤§å°

3. **max_window_sizeé™åˆ¶**ï¼š
   - å½“å‰å®ç°ï¼š`max_window_size = min(100, len(dsopt_data))`
   - å¦‚æœDSoptæ•°æ®é›†å¾ˆå¤§ï¼Œçª—å£å¤§å°é™åˆ¶ä¸º100
   - å¯èƒ½æ— æ³•æ‰¾åˆ°æœ€ä¼˜çª—å£å¤§å°

### 3.2 æ”¹è¿›å»ºè®®

**å¢åŠ max_window_sizeé™åˆ¶**ï¼š
```python
# å½“å‰å®ç°
max_window_size = min(100, len(dsopt_data))

# å»ºè®®ä¿®æ”¹
max_window_size = min(500, len(dsopt_data))  # å¢åŠ åˆ°500
```

**æ·»åŠ æ—©åœæœºåˆ¶**ï¼š
```python
# å¦‚æœè¿ç»­Nä¸ªçª—å£å¤§å°çš„FPRå˜åŒ–å°äºé˜ˆå€¼ï¼Œåˆ™åœæ­¢
prev_fpr = None
stable_count = 0
max_stable_count = 10

for window_size in range(1, max_window_size + 1):
    fpr = self.calculate_fpr_with_window(anomaly_decisions, true_labels, window_size)
    
    if prev_fpr is not None and abs(fpr - prev_fpr) < 0.0001:
        stable_count += 1
        if stable_count >= max_stable_count:
            print(f"âœ… FPR stabilized at window size {window_size}")
            break
    else:
        stable_count = 0
    
    prev_fpr = fpr
    
    if fpr == 0.0:
        best_window_size = window_size
        print(f"âœ… Found optimal window size ws* = {best_window_size}")
        break
```

## 4. è‡ªç¼–ç å™¨æ¨¡å‹åˆ†æ

### 4.1 è‡ªç¼–ç å™¨è®­ç»ƒåˆ†æ

**è®­ç»ƒè¿‡ç¨‹**ï¼š
```python
# trainer.py ç¬¬150-155è¡Œ
# ç¼–è¯‘æ¨¡å‹
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
    loss='mse',  # ä½¿ç”¨MSEä½œä¸ºæŸå¤±å‡½æ•°
    metrics=['mae']
)
```

**æŸå¤±å‡½æ•°**ï¼š
- ä½¿ç”¨MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰ä½œä¸ºæŸå¤±å‡½æ•°
- è‡ªç¼–ç å™¨çš„ç›®æ ‡æ˜¯å­¦ä¹ é‡å»ºè¾“å…¥æ•°æ®çš„èƒ½åŠ›
- é€šè¿‡æœ€å°åŒ–MSEæ¥ä¼˜åŒ–æ¨¡å‹å‚æ•°

### 4.2 è‡ªç¼–ç å™¨æ˜¯å¦æœ‰ç¼ºé™·ï¼Ÿ

**å¯èƒ½çš„é—®é¢˜**ï¼š

1. **é‡å»ºèƒ½åŠ›ä¸è¶³**ï¼š
   - å¦‚æœè‡ªç¼–ç å™¨é‡å»ºèƒ½åŠ›ä¸è¶³ï¼Œè‰¯æ€§æ ·æœ¬çš„MSEå¯èƒ½è¾ƒå¤§
   - å¯¼è‡´é˜ˆå€¼è¾ƒé«˜ï¼Œæ›´å¤šæ ·æœ¬è¢«åˆ¤å®šä¸ºå¼‚å¸¸

2. **è¿‡æ‹Ÿåˆ**ï¼š
   - å¦‚æœè‡ªç¼–ç å™¨è¿‡æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œå¯¹æ–°æ•°æ®çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®
   - å¯èƒ½å¯¼è‡´è‰¯æ€§æ ·æœ¬çš„MSEè¾ƒå¤§

3. **è®­ç»ƒä¸å……åˆ†**ï¼š
   - å¦‚æœè®­ç»ƒè½®æ•°ä¸è¶³ï¼Œæ¨¡å‹å¯èƒ½æ²¡æœ‰å……åˆ†å­¦ä¹ 
   - å¯èƒ½å¯¼è‡´é‡å»ºèƒ½åŠ›ä¸è¶³

### 4.3 éªŒè¯å»ºè®®

**åˆ†æè®­ç»ƒå†å²**ï¼š
```python
# æ·»åŠ è®­ç»ƒå†å²åˆ†æ
print(f"ğŸ“Š Training history analysis:")
print(f"   Initial train loss: {history_dict['loss'][0]:.6f}")
print(f"   Final train loss: {history_dict['loss'][-1]:.6f}")
print(f"   Initial val loss: {history_dict['val_loss'][0]:.6f}")
print(f"   Final val loss: {history_dict['val_loss'][-1]:.6f}")
print(f"   Best val loss: {best_val_loss:.6f}")
```

**åˆ†æé‡å»ºè¯¯å·®**ï¼š
```python
# åœ¨DSoptå’ŒDStstä¸Šåˆ†åˆ«è®¡ç®—MSE
dsopt_mse = self.calculate_reconstruction_error(dsopt_data)
dstst_mse = self.calculate_reconstruction_error(dstst_data)

print(f"ğŸ“Š MSE comparison:")
print(f"   DSopt MSE: mean={np.mean(dsopt_mse):.6f}, std={np.std(dsopt_mse):.6f}")
print(f"   DStst MSE: mean={np.mean(dstst_mse):.6f}, std={np.std(dstst_mse):.6f}")
```

## 5. é—®é¢˜æ€»ç»“ä¸è§£å†³æ–¹æ¡ˆ

### 5.1 ä¸ºä»€ä¹ˆDSoptä¸Šçš„åˆå§‹å¼‚å¸¸å€™é€‰æ•°é‡é‚£ä¹ˆå¤šï¼Ÿ

**å¯èƒ½åŸå› **ï¼š
1. **é˜ˆå€¼è®¾ç½®è¿‡é«˜**ï¼š`mean_mse + std_mse`å¯èƒ½è¿‡é«˜
2. **MSEåˆ†å¸ƒä¸å‡åŒ€**ï¼šMSEåˆ†å¸ƒå¯èƒ½å³åï¼Œå¯¼è‡´æ›´å¤šæ ·æœ¬è¢«åˆ¤å®šä¸ºå¼‚å¸¸
3. **è‡ªç¼–ç å™¨é‡å»ºèƒ½åŠ›ä¸è¶³**ï¼šè‰¯æ€§æ ·æœ¬çš„MSEå¯èƒ½è¾ƒå¤§

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. **è°ƒæ•´é˜ˆå€¼ç®—æ³•**ï¼š
   ```python
   # å½“å‰å®ç°
   tr_threshold = mean_mse + std_mse
   
   # å»ºè®®ä¿®æ”¹ï¼ˆæ›´ä¿å®ˆçš„é˜ˆå€¼ï¼‰
   tr_threshold = mean_mse + 2 * std_mse  # ä½¿ç”¨2å€æ ‡å‡†å·®
   ```

2. **ä½¿ç”¨ç™¾åˆ†ä½æ•°**ï¼š
   ```python
   # ä½¿ç”¨95ç™¾åˆ†ä½æ•°ä½œä¸ºé˜ˆå€¼
   tr_threshold = np.percentile(mse_values, 95)
   ```

3. **åˆ†æMSEåˆ†å¸ƒ**ï¼š
   ```python
   # æ·»åŠ MSEåˆ†å¸ƒåˆ†æ
   print(f"ğŸ“Š MSE distribution analysis:")
   print(f"   Skewness: {scipy.stats.skew(mse_values):.4f}")
   print(f"   Kurtosis: {scipy.stats.kurtosis(mse_values):.4f}")
   ```

### 5.2 ä¸ºä»€ä¹ˆæ»‘åŠ¨çª—å£æ€»æ˜¯è¦è®¾ç½®æˆæœ€å¤§ï¼Ÿ

**å¯èƒ½åŸå› **ï¼š
1. **åˆå§‹å¼‚å¸¸å€™é€‰æ•°é‡è¿‡å¤š**ï¼šéœ€è¦å¾ˆå¤§çš„çª—å£å¤§å°æ‰èƒ½é€šè¿‡å¤šæ•°æŠ•ç¥¨æ¶ˆé™¤è¯¯æŠ¥
2. **max_window_sizeé™åˆ¶è¿‡å°**ï¼šå½“å‰é™åˆ¶ä¸º100ï¼Œå¯èƒ½æ— æ³•æ‰¾åˆ°æœ€ä¼˜çª—å£å¤§å°
3. **å¤šæ•°æŠ•ç¥¨æœºåˆ¶çš„å±€é™æ€§**ï¼šçª—å£å¤§å°è¶Šå¤§ï¼Œéœ€è¦è¶Šå¤šçš„å¼‚å¸¸å†³ç­–æ‰èƒ½åˆ¤å®šä¸ºå¼‚å¸¸

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. **å¢åŠ max_window_sizeé™åˆ¶**ï¼š
   ```python
   max_window_size = min(500, len(dsopt_data))  # å¢åŠ åˆ°500
   ```

2. **æ·»åŠ æ—©åœæœºåˆ¶**ï¼š
   ```python
   # å¦‚æœè¿ç»­Nä¸ªçª—å£å¤§å°çš„FPRå˜åŒ–å°äºé˜ˆå€¼ï¼Œåˆ™åœæ­¢
   prev_fpr = None
   stable_count = 0
   max_stable_count = 10
   
   for window_size in range(1, max_window_size + 1):
       fpr = self.calculate_fpr_with_window(anomaly_decisions, true_labels, window_size)
       
       if prev_fpr is not None and abs(fpr - prev_fpr) < 0.0001:
           stable_count += 1
           if stable_count >= max_stable_count:
               print(f"âœ… FPR stabilized at window size {window_size}")
               break
       else:
           stable_count = 0
       
       prev_fpr = fpr
       
       if fpr == 0.0:
           best_window_size = window_size
           print(f"âœ… Found optimal window size ws* = {best_window_size}")
           break
   ```

3. **æ·»åŠ è‡ªé€‚åº”çª—å£å¤§å°**ï¼š
   ```python
   # æ ¹æ®DSoptæ•°æ®é›†çš„å¼‚å¸¸å€™é€‰æ•°é‡è‡ªé€‚åº”è°ƒæ•´çª—å£å¤§å°
   initial_anomaly_ratio = sum(anomaly_decisions) / len(anomaly_decisions)
   
   if initial_anomaly_ratio > 0.05:
       # åˆå§‹å¼‚å¸¸å€™é€‰æ¯”ä¾‹è¾ƒé«˜ï¼Œä½¿ç”¨æ›´å¤§çš„çª—å£å¤§å°
       max_window_size = min(500, len(dsopt_data))
   else:
       # åˆå§‹å¼‚å¸¸å€™é€‰æ¯”ä¾‹è¾ƒä½ï¼Œä½¿ç”¨è¾ƒå°çš„çª—å£å¤§å°
       max_window_size = min(100, len(dsopt_data))
   ```

### 5.3 è‡ªç¼–ç å™¨æ˜¯å¦æœ‰ç¼ºé™·ï¼Ÿ

**éªŒè¯å»ºè®®**ï¼š
1. **åˆ†æè®­ç»ƒå†å²**ï¼š
   ```python
   # æ·»åŠ è®­ç»ƒå†å²åˆ†æ
   print(f"ğŸ“Š Training history analysis:")
   print(f"   Initial train loss: {history_dict['loss'][0]:.6f}")
   print(f"   Final train loss: {history_dict['loss'][-1]:.6f}")
   print(f"   Initial val loss: {history_dict['val_loss'][0]:.6f}")
   print(f"   Final val loss: {history_dict['val_loss'][-1]:.6f}")
   print(f"   Best val loss: {best_val_loss:.6f}")
   ```

2. **åˆ†æé‡å»ºè¯¯å·®**ï¼š
   ```python
   # åœ¨DSoptå’ŒDStstä¸Šåˆ†åˆ«è®¡ç®—MSE
   dsopt_mse = self.calculate_reconstruction_error(dsopt_data)
   dstst_mse = self.calculate_reconstruction_error(dstst_data)
   
   print(f"ğŸ“Š MSE comparison:")
   print(f"   DSopt MSE: mean={np.mean(dsopt_mse):.6f}, std={np.std(dsopt_mse):.6f}")
   print(f"   DStst MSE: mean={np.mean(dstst_mse):.6f}, std={np.std(dstst_mse):.6f}")
   print(f"   MSE ratio: {np.mean(dstst_mse)/np.mean(dsopt_mse):.2f}")
   ```

3. **æ£€æŸ¥æ¨¡å‹æ€§èƒ½**ï¼š
   ```python
   # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿‡æ‹Ÿåˆ
   train_loss = history_dict['loss']
   val_loss = history_dict['val_loss']
   
   if val_loss[-1] > train_loss[-1] * 1.2:
       print(f"âš ï¸ Warning: Model may be overfitting!")
       print(f"   Final train loss: {train_loss[-1]:.6f}")
       print(f"   Final val loss: {val_loss[-1]:.6f}")
       print(f"   Overfitting ratio: {val_loss[-1]/train_loss[-1]:.2f}")
   ```

## 6. å®Œæ•´çš„ä¿®å¤å»ºè®®

### 6.1 çŸ­æœŸä¿®å¤ï¼ˆç«‹å³å®æ–½ï¼‰

1. **æ·»åŠ MSEåˆ†å¸ƒåˆ†æ**ï¼š
   ```python
   # åœ¨calculate_anomaly_thresholdæ–¹æ³•ä¸­æ·»åŠ 
   print(f"ğŸ“Š MSE distribution analysis:")
   print(f"   Percentiles:")
   for p in [50, 75, 90, 95, 99]:
       print(f"   {p}th percentile: {np.percentile(mse_values, p):.6f}")
   ```

2. **è°ƒæ•´é˜ˆå€¼ç®—æ³•**ï¼š
   ```python
   # æä¾›å¤šç§é˜ˆå€¼ç®—æ³•
   # æ–¹æ³•1ï¼šå‡å€¼+æ ‡å‡†å·®
   tr_threshold_1 = mean_mse + std_mse
   
   # æ–¹æ³•2ï¼šå‡å€¼+2*æ ‡å‡†å·®ï¼ˆæ›´ä¿å®ˆï¼‰
   tr_threshold_2 = mean_mse + 2 * std_mse
   
   # æ–¹æ³•3ï¼š95ç™¾åˆ†ä½æ•°
   tr_threshold_3 = np.percentile(mse_values, 95)
   
   # ä½¿ç”¨æ–¹æ³•3
   self.tr_threshold = tr_threshold_3
   ```

3. **å¢åŠ max_window_sizeé™åˆ¶**ï¼š
   ```python
   max_window_size = min(500, len(dsopt_data))
   ```

### 6.2 ä¸­æœŸæ”¹è¿›ï¼ˆé€æ­¥å®æ–½ï¼‰

1. **æ·»åŠ æ—©åœæœºåˆ¶**ï¼š
   ```python
   # å¦‚æœè¿ç»­Nä¸ªçª—å£å¤§å°çš„FPRå˜åŒ–å°äºé˜ˆå€¼ï¼Œåˆ™åœæ­¢
   prev_fpr = None
   stable_count = 0
   max_stable_count = 10
   
   for window_size in range(1, max_window_size + 1):
       fpr = self.calculate_fpr_with_window(anomaly_decisions, true_labels, window_size)
       
       if prev_fpr is not None and abs(fpr - prev_fpr) < 0.0001:
           stable_count += 1
           if stable_count >= max_stable_count:
               print(f"âœ… FPR stabilized at window size {window_size}")
               break
       else:
           stable_count = 0
       
       prev_fpr = fpr
       
       if fpr == 0.0:
           best_window_size = window_size
           print(f"âœ… Found optimal window size ws* = {best_window_size}")
           break
   ```

2. **æ·»åŠ è‡ªé€‚åº”çª—å£å¤§å°**ï¼š
   ```python
   # æ ¹æ®DSoptæ•°æ®é›†çš„å¼‚å¸¸å€™é€‰æ•°é‡è‡ªé€‚åº”è°ƒæ•´çª—å£å¤§å°
   initial_anomaly_ratio = sum(anomaly_decisions) / len(anomaly_decisions)
   
   if initial_anomaly_ratio > 0.05:
       # åˆå§‹å¼‚å¸¸å€™é€‰æ¯”ä¾‹è¾ƒé«˜ï¼Œä½¿ç”¨æ›´å¤§çš„çª—å£å¤§å°
       max_window_size = min(500, len(dsopt_data))
   else:
       # åˆå§‹å¼‚å¸¸å€™é€‰æ¯”ä¾‹è¾ƒä½ï¼Œä½¿ç”¨è¾ƒå°çš„çª—å£å¤§å°
       max_window_size = min(100, len(dsopt_data))
   ```

### 6.3 é•¿æœŸæ”¹è¿›ï¼ˆæ·±å…¥ç ”ç©¶ï¼‰

1. **ä¼˜åŒ–è‡ªç¼–ç å™¨æ¶æ„**ï¼š
   - å¢åŠ ç¼–ç å™¨å±‚æ•°
   - å¢åŠ éšè—å±‚ç»´åº¦
   - ä½¿ç”¨ä¸åŒçš„æ¿€æ´»å‡½æ•°

2. **ä½¿ç”¨æ›´å…ˆè¿›çš„å¼‚å¸¸æ£€æµ‹ç®—æ³•**ï¼š
   - åŸºäºå¯†åº¦çš„å¼‚å¸¸æ£€æµ‹
   - å­¤ç«‹æ£®æ—å¼‚å¸¸æ£€æµ‹
   - è‡ªç¼–ç å™¨+åˆ†ç±»å™¨ç»„åˆæ–¹æ³•

3. **æ·»åŠ è¯¦ç»†çš„æ€§èƒ½åˆ†æ**ï¼š
   - åˆ†æä¸åŒæ”»å‡»ç±»å‹çš„æ£€æµ‹æ€§èƒ½
   - åˆ†æä¸åŒæ”»å‡»ç±»å‹çš„MSEåˆ†å¸ƒ
   - åˆ†æä¸åŒæ”»å‡»ç±»å‹çš„æ··æ·†çŸ©é˜µ

## 7. ç»“è®º

### 7.1 MSEçš„å®šä¹‰

**MSEï¼ˆMean Squared Errorï¼‰**ï¼š
- è¡¨ç¤ºè‡ªç¼–ç å™¨é‡å»ºæ•°æ®çš„å¹³å‡è¯¯å·®
- è®¡ç®—å…¬å¼ï¼š`MSE = (1/n) * Î£(y_true - y_pred)^2`
- ç‰©ç†æ„ä¹‰ï¼šMSEè¶Šå°ï¼Œè¯´æ˜è‡ªç¼–ç å™¨é‡å»ºèƒ½åŠ›è¶Šå¥½

### 7.2 å¼‚å¸¸é˜ˆå€¼è®¡ç®—

**å½“å‰ç®—æ³•**ï¼š
- é˜ˆå€¼ = å‡å€¼ + æ ‡å‡†å·®
- åˆ¤å®šè§„åˆ™ï¼šMSE > é˜ˆå€¼ï¼Œåˆ™åˆ¤å®šä¸ºå¼‚å¸¸

**ä¸ºä»€ä¹ˆDSoptä¸Šçš„åˆå§‹å¼‚å¸¸å€™é€‰æ•°é‡é‚£ä¹ˆå¤šï¼Ÿ**
- å¯èƒ½åŸå› 1ï¼šé˜ˆå€¼è®¾ç½®è¿‡é«˜ï¼ˆ`mean_mse + std_mse`ï¼‰
- å¯èƒ½åŸå› 2ï¼šMSEåˆ†å¸ƒä¸å‡åŒ€ï¼ˆå³åï¼‰
- å¯èƒ½åŸå› 3ï¼šè‡ªç¼–ç å™¨é‡å»ºèƒ½åŠ›ä¸è¶³

### 7.3 ä¸ºä»€ä¹ˆæ»‘åŠ¨çª—å£æ€»æ˜¯è¦è®¾ç½®æˆæœ€å¤§ï¼Ÿ

**å½“å‰ç®—æ³•**ï¼š
- å¤šæ•°æŠ•ç¥¨æœºåˆ¶
- çª—å£å¤§å°ä¸ºNæ—¶ï¼Œéœ€è¦è¶…è¿‡N/2ä¸ªå¼‚å¸¸å†³ç­–æ‰èƒ½åˆ¤å®šä¸ºå¼‚å¸¸

**ä¸ºä»€ä¹ˆæ€»æ˜¯è¦è®¾ç½®æˆæœ€å¤§ï¼Ÿ**
- å¯èƒ½åŸå› 1ï¼šåˆå§‹å¼‚å¸¸å€™é€‰æ•°é‡è¿‡å¤š
- å¯èƒ½åŸå› 2ï¼šmax_window_sizeé™åˆ¶è¿‡å°ï¼ˆ100ï¼‰
- å¯èƒ½åŸå› 3ï¼šå¤šæ•°æŠ•ç¥¨æœºåˆ¶çš„å±€é™æ€§

### 7.4 è‡ªç¼–ç å™¨æ˜¯å¦æœ‰ç¼ºé™·ï¼Ÿ

**éªŒè¯å»ºè®®**ï¼š
- åˆ†æè®­ç»ƒå†å²
- åˆ†æé‡å»ºè¯¯å·®
- æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿‡æ‹Ÿåˆ

## 8. é™„å½•

### 8.1 æœ¯è¯­è¡¨

- **MSE**ï¼šå‡æ–¹è¯¯å·®ï¼ˆMean Squared Errorï¼‰
- **tr***ï¼šå¼‚å¸¸é˜ˆå€¼ï¼ˆThresholdï¼‰
- **ws***ï¼šæ»‘åŠ¨çª—å£å¤§å°ï¼ˆWindow Sizeï¼‰
- **FPR**ï¼šè¯¯æŠ¥ç‡ï¼ˆFalse Positive Rateï¼‰
- **TPR**ï¼šçœŸé˜³æ€§ç‡ï¼ˆTrue Positive Rateï¼‰
- **DSopt**ï¼šä¼˜åŒ–æ•°æ®é›†ï¼ˆOptimization Datasetï¼Œå…¨éƒ¨ä¸ºè‰¯æ€§ï¼‰
- **DStst**ï¼šæµ‹è¯•æ•°æ®é›†ï¼ˆTest Datasetï¼ŒåŒ…å«è‰¯æ€§+æ”»å‡»ï¼‰

### 8.2 å‚è€ƒæ–‡çŒ®

1. N-BaIoTæ•°æ®é›†ï¼šhttps://archive.ics.uci.edu/ml/datasets/n-baiot
2. è‡ªç¼–ç å™¨å¼‚å¸¸æ£€æµ‹ï¼šhttps://arxiv.org/abs/1901.03407
3. å¼‚å¸¸æ£€æµ‹é˜ˆå€¼æ–¹æ³•ï¼šhttps://en.wikipedia.org/wiki/Anomaly_detection

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**ï¼š2026-02-06
**æŠ¥å‘Šç‰ˆæœ¬**ï¼šv1.0
**ä½œè€…**ï¼šAI Assistant
