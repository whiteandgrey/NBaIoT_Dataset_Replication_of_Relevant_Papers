"""
å¼‚å¸¸æ£€æµ‹æ¨¡å— - é˜ˆå€¼è®¡ç®—ã€æ»‘åŠ¨çª—å£ä¼˜åŒ–ã€æ€§èƒ½è¯„ä¼°
"""
import os
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.metrics import precision_recall_curve, f1_score, confusion_matrix
import matplotlib.pyplot as plt


class AnomalyDetector:
    """å¼‚å¸¸æ£€æµ‹å™¨ç±»"""

    def __init__(self, config):
        """
        åˆå§‹åŒ–å¼‚å¸¸æ£€æµ‹å™¨

        Args:
            config: é…ç½®å¯¹è±¡
        """
        self.config = config
        self.model = None
        self.scaler = None
        self.tr_threshold = None
        self.ws_threshold = None

    def load_model(self, model_path):
        """
        åŠ è½½è®­ç»ƒå¥½çš„è‡ªç¼–ç å™¨æ¨¡å‹

        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„

        Returns:
            åŠ è½½çš„Kerasæ¨¡å‹
        """
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file not found: {model_path}")

        self.model = tf.keras.models.load_model(model_path)
        print(f"âœ… Model loaded from: {model_path}")
        return self.model

    def load_scaler(self, scaler_path):
        """
        åŠ è½½è®­ç»ƒå¥½çš„scaler

        Args:
            scaler_path: scaleræ–‡ä»¶è·¯å¾„

        Returns:
            åŠ è½½çš„scalerå¯¹è±¡
        """
        if not os.path.exists(scaler_path):
            raise FileNotFoundError(f"Scaler file not found: {scaler_path}")

        import joblib
        self.scaler = joblib.load(scaler_path)
        print(f"âœ… Scaler loaded from: {scaler_path}")
        return self.scaler

    def calculate_reconstruction_error(self, data):
        """
        è®¡ç®—é‡å»ºè¯¯å·®ï¼ˆMSEï¼‰

        Args:
            data: è¾“å…¥æ•°æ®

        Returns:
            é‡å»ºè¯¯å·®æ•°ç»„
        """
        if self.model is None:
            raise ValueError("Model not loaded. Call load_model() first.")

        if self.scaler is not None:
            data = self.scaler.transform(data)

        # é¢„æµ‹é‡å»ºæ•°æ®
        reconstructed = self.model.predict(data, verbose=0)
        
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„MSE
        mse = np.mean(np.power(data - reconstructed, 2), axis=1)
        
        print(f"ğŸ“Š Reconstruction error calculated: {len(mse)} samples")
        print(f"   MSE stats: min={mse.min():.6f}, max={mse.max():.6f}, mean={mse.mean():.6f}, std={mse.std():.6f}")
        
        return mse

    def calculate_anomaly_threshold(self, dsopt_data):
        """
        è®¡ç®—å¼‚å¸¸é˜ˆå€¼ tr*

        Args:
            dsopt_data: DSoptæ•°æ®é›†

        Returns:
            å¼‚å¸¸é˜ˆå€¼ tr*
        """
        print(f"\n{'=' * 60}")
        print("CALCULATING ANOMALY THRESHOLD (tr*)")
        print(f"{'=' * 60}")

        # è®¡ç®—DSoptä¸Šçš„MSE
        mse_values = self.calculate_reconstruction_error(dsopt_data)

        # è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
        mean_mse = np.mean(mse_values)
        std_mse = np.std(mse_values)

        # è®¡ç®—é˜ˆå€¼
        self.tr_threshold = mean_mse + std_mse

        print(f"ğŸ“Š DSopt MSE statistics:")
        print(f"   Mean: {mean_mse:.6f}")
        print(f"   Std: {std_mse:.6f}")
        print(f"   Calculated threshold tr*: {self.tr_threshold:.6f}")

        return self.tr_threshold

    def calculate_fpr_with_window(self, anomaly_decisions, true_labels, window_size):
        """
        ä½¿ç”¨æ»‘åŠ¨çª—å£è®¡ç®—è¯¯æŠ¥ç‡ï¼ˆFPRï¼‰

        Args:
            anomaly_decisions: åˆå§‹å¼‚å¸¸å†³ç­–ï¼ˆ0/1ï¼‰
            true_labels: çœŸå®æ ‡ç­¾ï¼ˆ0=è‰¯æ€§ï¼Œ1=æ¶æ„ï¼‰
            window_size: æ»‘åŠ¨çª—å£å¤§å°

        Returns:
            è¯¯æŠ¥ç‡ï¼ˆFPRï¼‰
        """
        if len(anomaly_decisions) != len(true_labels):
            raise ValueError("anomaly_decisions and true_labels must have the same length")

        windowed_decisions = []
        n_samples = len(anomaly_decisions)

        # åº”ç”¨æ»‘åŠ¨çª—å£å¤šæ•°æŠ•ç¥¨
        for i in range(n_samples):
            start = max(0, i - window_size + 1)
            window = anomaly_decisions[start:i+1]
            if len(window) >= window_size // 2:
                # å¤šæ•°æŠ•ç¥¨
                window_decision = 1 if sum(window) > len(window) / 2 else 0
            else:
                # çª—å£å¤ªå°ï¼Œç›´æ¥ä½¿ç”¨å½“å‰å†³ç­–
                window_decision = anomaly_decisions[i]
            windowed_decisions.append(window_decision)

        # è®¡ç®—æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(true_labels, windowed_decisions)
        
        # å¤„ç†ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœæ··æ·†çŸ©é˜µä¸æ˜¯2x2ï¼Œæ‰‹åŠ¨è®¡ç®—
        if cm.shape == (1, 1):
            # æ‰€æœ‰é¢„æµ‹éƒ½æ˜¯0ï¼ˆè‰¯æ€§ï¼‰
            tn = cm[0, 0]
            fp = 0
            fn = 0
            tp = 0
        else:
            # æ­£å¸¸æƒ…å†µï¼š2x2æ··æ·†çŸ©é˜µ
            tn, fp, fn, tp = cm.ravel()

        # è®¡ç®—è¯¯æŠ¥ç‡
        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0
        return fpr

    def optimize_window_size(self, dsopt_data, tr_threshold):
        """
        å¯»æ‰¾æœ€å°çš„çª—å£å¤§å° ws*ï¼Œä½¿å¾—åœ¨DSoptä¸Šå®ç°0%çš„è¯¯æŠ¥ç‡

        Args:
            dsopt_data: DSoptæ•°æ®é›†ï¼ˆå…¨éƒ¨ä¸ºè‰¯æ€§æ•°æ®ï¼‰
            tr_threshold: å¼‚å¸¸é˜ˆå€¼

        Returns:
            æœ€ä¼˜çª—å£å¤§å° ws*
        """
        print(f"\n{'=' * 60}")
        print("OPTIMIZING WINDOW SIZE (ws*)")
        print(f"{'=' * 60}")

        # è®¡ç®—DSoptä¸Šçš„MSE
        mse_values = self.calculate_reconstruction_error(dsopt_data)

        # ç”Ÿæˆåˆå§‹å¼‚å¸¸å†³ç­–ï¼ˆ>tr*=1ï¼Œå¦åˆ™=0ï¼‰
        anomaly_decisions = (mse_values > tr_threshold).astype(int)

        # DSoptå…¨éƒ¨æ˜¯è‰¯æ€§æ•°æ®ï¼ŒçœŸå®æ ‡ç­¾å…¨ä¸º0
        true_labels = np.zeros(len(dsopt_data), dtype=int)

        print(f"ğŸ“Š Initial anomaly detection on DSopt:")
        print(f"   Total samples: {len(dsopt_data)}")
        print(f"   Initial anomaly candidates: {sum(anomaly_decisions)} ({sum(anomaly_decisions)/len(dsopt_data)*100:.2f}%)")

        # å¯»æ‰¾æœ€å°çš„çª—å£å¤§å°
        max_window_size = min(self.config.MAX_WINDOW_SIZE, len(dsopt_data))
        best_window_size = max_window_size

        for window_size in range(self.config.MIN_WINDOW_SIZE, max_window_size + 1, self.config.WINDOW_SIZE_STEP):
            fpr = self.calculate_fpr_with_window(anomaly_decisions, true_labels, window_size)
            
            if window_size % 10 == 0:
                print(f"   Window size {window_size}: FPR = {fpr:.4f}")

            if fpr == 0.0:
                best_window_size = window_size
                print(f"âœ… Found optimal window size ws* = {best_window_size}")
                break

        self.ws_threshold = best_window_size
        print(f"ğŸ“Š Final optimal window size: {self.ws_threshold}")

        return self.ws_threshold

    def detect_anomalies(self, data, tr_threshold=None, ws_threshold=None):
        """
        ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å’Œé˜ˆå€¼æ£€æµ‹å¼‚å¸¸

        Args:
            data: è¾“å…¥æ•°æ®
            tr_threshold: å¼‚å¸¸é˜ˆå€¼ï¼ˆå¯é€‰ï¼Œä½¿ç”¨å·²è®¡ç®—çš„é˜ˆå€¼ï¼‰
            ws_threshold: æ»‘åŠ¨çª—å£å¤§å°ï¼ˆå¯é€‰ï¼Œä½¿ç”¨å·²è®¡ç®—çš„é˜ˆå€¼ï¼‰

        Returns:
            å¼‚å¸¸æ£€æµ‹ç»“æœï¼ˆ0=è‰¯æ€§ï¼Œ1=æ¶æ„ï¼‰
        """
        if tr_threshold is None:
            tr_threshold = self.tr_threshold
        if ws_threshold is None:
            ws_threshold = self.ws_threshold

        if tr_threshold is None:
            raise ValueError("tr_threshold not set. Call calculate_anomaly_threshold() first.")
        if ws_threshold is None:
            raise ValueError("ws_threshold not set. Call optimize_window_size() first.")

        # è®¡ç®—MSE
        mse_values = self.calculate_reconstruction_error(data)

        # ç”Ÿæˆåˆå§‹å¼‚å¸¸å†³ç­–
        initial_decisions = (mse_values > tr_threshold).astype(int)

        # åº”ç”¨æ»‘åŠ¨çª—å£å¤šæ•°æŠ•ç¥¨
        final_decisions = []
        n_samples = len(initial_decisions)

        for i in range(n_samples):
            start = max(0, i - ws_threshold + 1)
            window = initial_decisions[start:i+1]
            if len(window) >= ws_threshold // 2:
                # å¤šæ•°æŠ•ç¥¨
                window_decision = 1 if sum(window) > len(window) / 2 else 0
            else:
                # çª—å£å¤ªå°ï¼Œç›´æ¥ä½¿ç”¨å½“å‰å†³ç­–
                window_decision = initial_decisions[i]
            final_decisions.append(window_decision)

        final_decisions = np.array(final_decisions)
        print(f"ğŸ“Š Anomaly detection results:")
        print(f"   Total samples: {n_samples}")
        print(f"   Detected anomalies: {sum(final_decisions)} ({sum(final_decisions)/n_samples*100:.2f}%)")

        return final_decisions, mse_values

    def evaluate_performance(self, data, true_labels, tr_threshold=None, ws_threshold=None):
        """
        è¯„ä¼°å¼‚å¸¸æ£€æµ‹æ€§èƒ½

        Args:
            data: è¾“å…¥æ•°æ®
            true_labels: çœŸå®æ ‡ç­¾ï¼ˆ0=è‰¯æ€§ï¼Œ1=æ¶æ„ï¼‰
            tr_threshold: å¼‚å¸¸é˜ˆå€¼
            ws_threshold: æ»‘åŠ¨çª—å£å¤§å°

        Returns:
            æ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        print(f"\n{'=' * 60}")
        print("EVALUATING DETECTION PERFORMANCE")
        print(f"{'=' * 60}")

        # æ£€æµ‹å¼‚å¸¸
        predictions, mse_values = self.detect_anomalies(data, tr_threshold, ws_threshold)

        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        tn, fp, fn, tp = confusion_matrix(true_labels, predictions).ravel()

        # å‡†ç¡®ç‡
        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0.0

        # ç²¾ç¡®ç‡
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0

        # å¬å›ç‡ï¼ˆTPRï¼‰
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0

        # è¯¯æŠ¥ç‡ï¼ˆFPRï¼‰
        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0

        # F1åˆ†æ•°
        f1 = f1_score(true_labels, predictions) if (tp + fp + fn) > 0 else 0.0

        # è®¡ç®—ROC AUC
        from sklearn.metrics import roc_auc_score
        roc_auc = roc_auc_score(true_labels, mse_values)

        # è®¡ç®—PR AUC
        precision_vals, recall_vals, _ = precision_recall_curve(true_labels, mse_values)
        from sklearn.metrics import auc
        pr_auc = auc(recall_vals, precision_vals)

        performance = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'fpr': fpr,
            'f1': f1,
            'roc_auc': roc_auc,
            'pr_auc': pr_auc,
            'confusion_matrix': {
                'tn': tn,
                'fp': fp,
                'fn': fn,
                'tp': tp
            }
        }

        print(f"ğŸ“Š Performance metrics:")
        print(f"   Accuracy: {accuracy:.4f}")
        print(f"   Precision: {precision:.4f}")
        print(f"   Recall (TPR): {recall:.4f}")
        print(f"   FPR: {fpr:.4f}")
        print(f"   F1 Score: {f1:.4f}")
        print(f"   ROC AUC: {roc_auc:.4f}")
        print(f"   PR AUC: {pr_auc:.4f}")
        print(f"   Confusion Matrix:")
        print(f"      TN: {tn}, FP: {fp}")
        print(f"      FN: {fn}, TP: {tp}")

        return performance

    def plot_performance_metrics(self, performance, save_dir=None):
        """
        ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡å›¾è¡¨

        Args:
            performance: æ€§èƒ½æŒ‡æ ‡å­—å…¸
            save_dir: ä¿å­˜ç›®å½•ï¼ˆå¯é€‰ï¼‰
        """
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)

        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        cm = np.array([[performance['confusion_matrix']['tn'], performance['confusion_matrix']['fp']],
                       [performance['confusion_matrix']['fn'], performance['confusion_matrix']['tp']]])

        plt.figure(figsize=(8, 6))
        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
        plt.title('Confusion Matrix')
        plt.colorbar()
        tick_marks = np.arange(2)
        plt.xticks(tick_marks, ['Benign', 'Malicious'])
        plt.yticks(tick_marks, ['Benign', 'Malicious'])

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        thresh = cm.max() / 2.
        for i, j in np.ndindex(cm.shape):
            plt.text(j, i, format(cm[i, j], 'd'),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")

        plt.tight_layout()
        plt.ylabel('True label')
        plt.xlabel('Predicted label')

        if save_dir:
            save_path = os.path.join(save_dir, 'confusion_matrix.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… Confusion matrix saved to: {save_path}")
        else:
            plt.show()

        # ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡æ¡å½¢å›¾
        metrics = ['Accuracy', 'Precision', 'Recall (TPR)', 'F1 Score', 'ROC AUC', 'PR AUC']
        values = [performance['accuracy'], performance['precision'], performance['recall'],
                  performance['f1'], performance['roc_auc'], performance['pr_auc']]

        plt.figure(figsize=(10, 6))
        bars = plt.bar(metrics, values, color='skyblue')
        plt.title('Performance Metrics')
        plt.ylim(0, 1.1)
        plt.ylabel('Score')
        plt.xticks(rotation=45, ha='right')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                     f'{height:.4f}', ha='center', va='bottom')

        plt.tight_layout()

        if save_dir:
            save_path = os.path.join(save_dir, 'performance_metrics.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… Performance metrics plot saved to: {save_path}")
        else:
            plt.show()

    def plot_reconstruction_error(self, mse_values, true_labels, save_dir=None):
        """
        ç»˜åˆ¶é‡å»ºè¯¯å·®åˆ†å¸ƒ

        Args:
            mse_values: é‡å»ºè¯¯å·®æ•°ç»„
            true_labels: çœŸå®æ ‡ç­¾
            save_dir: ä¿å­˜ç›®å½•ï¼ˆå¯é€‰ï¼‰
        """
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)

        plt.figure(figsize=(10, 6))

        # åˆ†ç¦»è‰¯æ€§å’Œæ¶æ„æ•°æ®çš„MSE
        benign_mse = mse_values[true_labels == 0]
        malicious_mse = mse_values[true_labels == 1]

        # ç»˜åˆ¶ç›´æ–¹å›¾
        plt.hist(benign_mse, bins=50, alpha=0.5, label='Benign', color='green')
        plt.hist(malicious_mse, bins=50, alpha=0.5, label='Malicious', color='red')

        # ç»˜åˆ¶é˜ˆå€¼çº¿
        if self.tr_threshold:
            plt.axvline(x=self.tr_threshold, color='blue', linestyle='--', label=f'Threshold tr* = {self.tr_threshold:.6f}')

        plt.title('Reconstruction Error Distribution')
        plt.xlabel('MSE')
        plt.ylabel('Frequency')
        plt.legend()
        plt.grid(alpha=0.3)

        if save_dir:
            save_path = os.path.join(save_dir, 'reconstruction_error_distribution.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… Reconstruction error distribution saved to: {save_path}")
        else:
            plt.show()
